{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Engbasemhamada/NYC-Taxi-Fare-Prediction/blob/main/scratchpad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIYdn1woOS1n",
        "outputId": "3c8775ec-c09a-47ed-f254-3ee43cc3c6ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Data Loaded Successfully!\n",
            "Shape: (50000, 26)\n",
            "Columns: ['User ID', 'User Name', 'Driver Name', 'Car Condition', 'Weather', 'Traffic Condition', 'key', 'fare_amount', 'pickup_datetime', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'passenger_count', 'hour', 'day', 'month', 'weekday', 'year', 'jfk_dist', 'ewr_dist', 'lga_dist', 'sol_dist', 'nyc_dist', 'distance', 'bearing']\n",
            "\n",
            "ğŸ“‹ Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 5 ØµÙÙˆÙ:\n",
            "    User ID          User Name       Driver Name Car Condition Weather  \\\n",
            "0  KHVrEVlD     Kimberly Adams        Amy Butler     Very Good   windy   \n",
            "1  lPxIuEri       Justin Tapia  Hannah Zimmerman     Excellent  cloudy   \n",
            "2  gsVN8JLS    Elizabeth Lopez    Amanda Jackson           Bad  stormy   \n",
            "3  9I7kWFgd      Steven Wilson          Amy Horn     Very Good  stormy   \n",
            "4  8QN5ZaGN  Alexander Andrews  Cassandra Larson           Bad  stormy   \n",
            "\n",
            "   Traffic Condition      key  fare_amount  pickup_datetime  pickup_longitude  \\\n",
            "0  Congested Traffic  26:21.0          4.5  6/15/2009 17:26         -1.288826   \n",
            "1       Flow Traffic  52:16.0         16.9   1/5/2010 16:52         -1.291824   \n",
            "2  Congested Traffic  35:00.0          5.7   8/18/2011 0:35         -1.291242   \n",
            "3       Flow Traffic  30:42.0          7.7   4/21/2012 4:30         -1.291319   \n",
            "4  Congested Traffic  51:00.0          5.3    3/9/2010 7:51         -1.290987   \n",
            "\n",
            "   ...  month  weekday  year   jfk_dist   ewr_dist   lga_dist   sol_dist  \\\n",
            "0  ...      6        0  2009  20.265840  55.176046  14.342611  34.543548   \n",
            "1  ...      1        1  2010  44.667679  31.832358  23.130775  15.125872   \n",
            "2  ...      8        3  2011  43.597686  33.712082  19.865289  17.722624   \n",
            "3  ...      4        5  2012  42.642965  32.556289  21.063132  15.738963   \n",
            "4  ...      3        1  2010  43.329953  39.406828  15.219339  23.732406   \n",
            "\n",
            "    nyc_dist  distance   bearing  \n",
            "0  27.572573  1.030764 -2.918897  \n",
            "1   8.755732  8.450134 -0.375217  \n",
            "2   9.847344  1.389525  2.599961  \n",
            "3   7.703421  2.799270  0.133905  \n",
            "4  15.600745  1.999157 -0.502703  \n",
            "\n",
            "[5 rows x 26 columns]\n",
            "\n",
            "â„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 26 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   User ID            50000 non-null  object \n",
            " 1   User Name          50000 non-null  object \n",
            " 2   Driver Name        50000 non-null  object \n",
            " 3   Car Condition      50000 non-null  object \n",
            " 4   Weather            50000 non-null  object \n",
            " 5   Traffic Condition  50000 non-null  object \n",
            " 6   key                50000 non-null  object \n",
            " 7   fare_amount        50000 non-null  float64\n",
            " 8   pickup_datetime    50000 non-null  object \n",
            " 9   pickup_longitude   50000 non-null  float64\n",
            " 10  pickup_latitude    50000 non-null  float64\n",
            " 11  dropoff_longitude  50000 non-null  float64\n",
            " 12  dropoff_latitude   50000 non-null  float64\n",
            " 13  passenger_count    50000 non-null  int64  \n",
            " 14  hour               50000 non-null  int64  \n",
            " 15  day                50000 non-null  int64  \n",
            " 16  month              50000 non-null  int64  \n",
            " 17  weekday            50000 non-null  int64  \n",
            " 18  year               50000 non-null  int64  \n",
            " 19  jfk_dist           50000 non-null  float64\n",
            " 20  ewr_dist           50000 non-null  float64\n",
            " 21  lga_dist           50000 non-null  float64\n",
            " 22  sol_dist           50000 non-null  float64\n",
            " 23  nyc_dist           50000 non-null  float64\n",
            " 24  distance           50000 non-null  float64\n",
            " 25  bearing            50000 non-null  float64\n",
            "dtypes: float64(12), int64(6), object(8)\n",
            "memory usage: 9.9+ MB\n",
            "None\n",
            "\n",
            "ğŸ§© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ© Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©:\n",
            "User ID              0\n",
            "User Name            0\n",
            "Driver Name          0\n",
            "Car Condition        0\n",
            "Weather              0\n",
            "Traffic Condition    0\n",
            "key                  0\n",
            "fare_amount          0\n",
            "pickup_datetime      0\n",
            "pickup_longitude     0\n",
            "pickup_latitude      0\n",
            "dropoff_longitude    0\n",
            "dropoff_latitude     0\n",
            "passenger_count      0\n",
            "hour                 0\n",
            "day                  0\n",
            "month                0\n",
            "weekday              0\n",
            "year                 0\n",
            "jfk_dist             0\n",
            "ewr_dist             0\n",
            "lga_dist             0\n",
            "sol_dist             0\n",
            "nyc_dist             0\n",
            "distance             0\n",
            "bearing              0\n",
            "dtype: int64\n",
            "\n",
            "âœ… Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© - Ù„Ø§ ØªÙˆØ¬Ø¯ Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø©:\n",
            "0 missing values remaining.\n",
            "\n",
            "ğŸ“Š Train/Test Shapes: (40000, 25) (10000, 25)\n",
            "âœ… ØªÙ… ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Final Internship Task - Data Preprocessing, Model Building, Hyperparameter Tuning\n",
        "Team: GDSC (Prepared by Eng. Bassem Hamada)\n",
        "\"\"\"\n",
        "\n",
        "# =============================\n",
        "# ğŸ“¦ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª\n",
        "# =============================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =============================\n",
        "# ğŸ“‚ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "# =============================\n",
        "data = pd.read_csv(\"final_internship_data.csv\")\n",
        "\n",
        "print(\"âœ… Data Loaded Successfully!\")\n",
        "print(\"Shape:\", data.shape)\n",
        "print(\"Columns:\", data.columns.tolist())\n",
        "\n",
        "# =============================\n",
        "# ğŸ” Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "# =============================\n",
        "print(\"\\nğŸ“‹ Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 5 ØµÙÙˆÙ:\")\n",
        "print(data.head())\n",
        "\n",
        "print(\"\\nâ„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©:\")\n",
        "print(data.info())\n",
        "\n",
        "# =============================\n",
        "# ğŸ§¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ©\n",
        "# =============================\n",
        "# Ø­Ø³Ø§Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ© ÙÙŠ ÙƒÙ„ Ø¹Ù…ÙˆØ¯\n",
        "print(\"\\nğŸ§© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ© Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Ø­Ø°Ù Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù„ÙŠ ÙÙŠÙ‡Ø§ Ù‚ÙŠÙ…Ø© Ù…ÙÙ‚ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù\n",
        "data = data[data[\"fare_amount\"].notna()]\n",
        "\n",
        "# Ù…Ù„Ø¡ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ø¨Ø§Ù„Ù…ØªÙˆØ³Ø·\n",
        "num_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "for col in num_cols:\n",
        "    data[col].fillna(data[col].mean(), inplace=True)\n",
        "\n",
        "# Ù…Ù„Ø¡ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ø§Ù„Ù†ØµÙŠØ© Ø¨Ø£ÙƒØ«Ø± Ù‚ÙŠÙ…Ø© ØªÙƒØ±Ø§Ø±Ù‹Ø§\n",
        "cat_cols = data.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "for col in cat_cols:\n",
        "    data[col].fillna(data[col].mode()[0], inplace=True)\n",
        "\n",
        "print(\"\\nâœ… Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© - Ù„Ø§ ØªÙˆØ¬Ø¯ Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø©:\")\n",
        "print(data.isnull().sum().sum(), \"missing values remaining.\")\n",
        "\n",
        "# =============================\n",
        "# ğŸ”  ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ø±Ù‚Ù…ÙŠØ©\n",
        "# =============================\n",
        "le = LabelEncoder()\n",
        "for col in cat_cols:\n",
        "    data[col] = le.fit_transform(data[col])\n",
        "\n",
        "# =============================\n",
        "# ğŸ¯ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù\n",
        "# =============================\n",
        "target = \"fare_amount\"\n",
        "X = data.drop(columns=[target])\n",
        "y = data[target]\n",
        "\n",
        "# =============================\n",
        "# âœ‚ï¸ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ø®ØªØ¨Ø§Ø±\n",
        "# =============================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "print(\"\\nğŸ“Š Train/Test Shapes:\", X_train.shape, X_test.shape)\n",
        "\n",
        "# =============================\n",
        "# âš™ï¸ ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù‚ÙŠÙ… (Standardization)\n",
        "# =============================\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "print(\"âœ… ØªÙ… ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­\")\n",
        "\n",
        "# =============================\n",
        "# ğŸ§  Ø¨Ù†Ø§Ø¡ Ù…ÙˆØ¯ÙŠÙ„ Ù…Ø¨Ø¯Ø¦ÙŠ (Baseline Model)\n",
        "# =============================\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Ø§Ù„ØªÙ†Ø¨Ø¤\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(\"\\nğŸ“ˆ Baseline RandomForest Results:\")\n",
        "print(f\"RÂ² Score: {r2:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "\n",
        "# =============================\n",
        "# ğŸ” Hyperparameter Tuning\n",
        "# =============================\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 200, 300],\n",
        "    \"max_depth\": [10, 20, None],\n",
        "    \"min_samples_split\": [2, 5, 10]\n",
        "}\n",
        "\n",
        "print(\"\\nğŸš€ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø¶Ø¨Ø· Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª (Hyperparameter Tuning)...\")\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=RandomForestRegressor(random_state=42),\n",
        "    param_grid=param_grid,\n",
        "    cv=3,\n",
        "    scoring=\"r2\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nâœ… Ø£ÙØ¶Ù„ Ù…Ø¹Ø§Ù…Ù„Ø§Øª ØªÙ… Ø¥ÙŠØ¬Ø§Ø¯Ù‡Ø§:\")\n",
        "print(grid.best_params_)\n",
        "\n",
        "# =============================\n",
        "# ğŸ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙØ¶Ù„\n",
        "# =============================\n",
        "best_model = grid.best_estimator_\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "\n",
        "best_r2 = r2_score(y_test, y_pred_best)\n",
        "best_rmse = np.sqrt(mean_squared_error(y_test, y_pred_best))\n",
        "\n",
        "print(\"\\nğŸŒŸ Final Model Performance:\")\n",
        "print(f\"Best RÂ² Score: {best_r2:.4f}\")\n",
        "print(f\"Best RMSE: {best_rmse:.4f}\")\n",
        "\n",
        "# =============================\n",
        "# ğŸ’¾ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù…Ù„Ù\n",
        "# =============================\n",
        "results = pd.DataFrame({\n",
        "    \"Model\": [\"RandomForestRegressor\"],\n",
        "    \"R2_Score\": [best_r2],\n",
        "    \"RMSE\": [best_rmse],\n",
        "    \"Best_Params\": [str(grid.best_params_)]\n",
        "})\n",
        "results.to_csv(\"model_results_summary.csv\", index=False)\n",
        "print(\"\\nğŸ“ Saved results to 'model_results_summary.csv'\")\n",
        "\n",
        "# =============================\n",
        "# ğŸ‰ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©\n",
        "# =============================\n",
        "print(\"\\nâœ… Task Completed Successfully by Eng. Bassem Hamada (GDSC Team) âœ…\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pATNUu5DpVw9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "scratchpad",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}